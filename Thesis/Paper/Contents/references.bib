@article{DroneschasingDrones,
  title={Drones Chasing Drones: Reinforcement Learning and Deep Search Area Proposal},
  author={Akhloufi, Moulay A and Arola, Sebastien and Bonnet, Alexandre},
  journal={Drones},
  volume={3},
  number={3},
  pages={58},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{DroneRLUsingTransferLearning,
  title={Autonomous Navigation via Deep Reinforcement Learning for Resource Constraint Edge Nodes Using Transfer Learning},
  author={Anwar, Aqeel and Raychowdhury, Arijit},
  journal={IEEE Access},
  volume={8},
  pages={26549--26560},
  year={2020},
  publisher={IEEE}
}

@inproceedings{RLisSuperannoying,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{DQNprovedConvergence,
  title={A theoretical analysis of deep Q-learning},
  author={Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
  booktitle={Learning for Dynamics and Control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

@article{prioritizedreplay,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{comparisonofarchitectures,
  title={Comparison of neural network architectures for spectrum sensing},
  author={Ye, Ziyu and Gilman, Andrew and Peng, Qihang and Levick, Kelly and Cosman, Pamela and Milstein, Larry},
  booktitle={2019 IEEE Globecom Workshops (GC Wkshps)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@article{staterepresentation,
  title={Selecting the state-representation in reinforcement learning},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Ryabko, Daniil},
  journal={arXiv preprint arXiv:1302.2552},
  year={2013}
}

@inproceedings{rlanoverview,
  title={Deep reinforcement learning: an overview},
  author={Mousavi, Seyed Sajad and Schukat, Michael and Howley, Enda},
  booktitle={Proceedings of SAI Intelligent Systems Conference},
  pages={426--440},
  year={2016},
  organization={Springer}
}

@article{ppo-paper,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@ARTICLE{policygradients,
  author={I. {Grondman} and L. {Busoniu} and G. A. D. {Lopes} and R. {Babuska}},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 
  title={A Survey of Actor-Critic Reinforcement Learning: Standard and Natural Policy Gradients}, 
  year={2012},
  volume={42},
  number={6},
  pages={1291-1307},
  doi={10.1109/TSMCC.2012.2218595}}

@article{rlsolvingatari,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@misc{TransferLearningGithub,
  author = {aqeelanwar},
  title = {Deep Reinforcement Learning with Transfer Learning - Simulated Drone and Environment},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished={\url{https://www.github.com/aqeelanwar/DRLwithTL}}
}

@misc{stereopi, 
title = {StereoPi},
howpublished={\url{https://stereopi.com/#home}}, 
journal={StereoPi}, 
year={2015}
}

@misc{TFAgents,
  title = { {TF-Agents}: A library for Reinforcement Learning in TensorFlow},
  author = {Sergio Guadarrama and Anoop Korattikara and Oscar Ramirez and
     Pablo Castro and Ethan Holly and Sam Fishman and Ke Wang and
     Ekaterina Gonina and Neal Wu and Efi Kokiopoulou and Luciano Sbaiz and
     Jamie Smith and Gábor Bartók and Jesse Berent and Chris Harris and
     Vincent Vanhoucke and Eugene Brevdo},
  howpublished={\url{"https://github.com/tensorflow/agents"}},
  year = 2018,
  note = "[Online; accessed 25-June-2019]"
}

@article{mAP,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, Mark and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={International journal of computer vision},
  volume={88},
  number={2},
  pages={303--338},
  year={2010},
  publisher={Springer}
}

 @misc{riseofneuralnets, 
  title={2010 – 2019: The rise of deep learning}, 
  howpublished={\url{https://thenextweb.com/artificial-intelligence/2020/01/02/2010-2019-the-rise-of-deep-learning/}}, 
  journal={The Next Web}, 
  author={Greene, Tristan}, 
  year={2020}, 
  month={Jan}
} 

@book{RLBook, 
  place={Massachusetts}, 
  title={Reinforcement Learning: An Introduction}, 
  publisher={MIT Press Ltd}, 
  author={Sutton, Richard S. and Bach, Francis and Barto, Andrew G.}, 
  year={2018}
}

@article{application1cardiac,
  title={Unmanned aerial vehicles (drones) in out-of-hospital-cardiac-arrest},
  author={Claesson, A and Fredman, D and Svensson, L and Ringh, M and Hollenberg, J and Nordberg, P and Rosenqvist, M and Djarv, T and {\"O}sterberg, S and Lennartsson, J and others},
  journal={Scandinavian journal of trauma, resuscitation and emergency medicine},
  volume={24},
  number={1},
  pages={124},
  year={2016},
  publisher={Springer}
}

@article{application2forestfires,
  title={Early forest fire detection and verification using optical smoke, gas and microwave sensors},
  author={Kr{\"u}ll, Wolfgang and Tobera, Robert and Willms, Ingolf and Essen, Helmut and von Wahl, Nora},
  journal={Procedia Engineering},
  volume={45},
  pages={584--594},
  year={2012},
  publisher={Elsevier}
}

@misc{embeddedsystem, title={What is an Embedded System? Definition and FAQs}, 
  howpublished={\url{https://www.omnisci.com/technical-glossary/embedded-systems}}, 
  journal={OmniSci}, 
  publisher={OmniSci}
}

@misc{neuralnets, 
  title={Explained: Neural networks}, 
  howpublished={\url{https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414}}, 
  journal={MIT News | Massachusetts Institute of Technology}, 
  publisher={MIT News Office}, 
  author={Hardesty, Larry}, 
  year={2017}, 
  month={Apr}
}

@article{firstcnn,
issn = {1573-1405},
journal = {International journal of computer vision},
pages = {211--252},
volume = {115},
publisher = {Springer Science and Business Media LLC},
number = {3},
year = {2015},
title = {ImageNet Large Scale Visual Recognition Challenge},
copyright = {Springer Science+Business Media New York 2015},
language = {eng},
address = {New York},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C and Fei-Fei, Li},
keywords = {Pattern Recognition ; Large-scale ; Dataset ; Computer Science ; Computer Imaging, Vision, Pattern Recognition and Graphics ; Image Processing and Computer Vision ; Object detection ; Artificial Intelligence (incl. Robotics) ; Benchmark ; Object recognition ; Machine vision},
}

@article{PPO,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{A3C,
  title={Reinforcement learning through asynchronous advantage actor-critic on a gpu},
  author={Babaeizadeh, Mohammad and Frosio, Iuri and Tyree, Stephen and Clemons, Jason and Kautz, Jan},
  journal={arXiv preprint arXiv:1611.06256},
  year={2016}
}

@article{SAC,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

 @misc{depthimageexample, 
  title={Z-Depth Map - Expanding EXIF Data for More Powerful Post-Processing: THEME},  
  journal={THEME | More Photography}, 
  publisher={Theme}, 
  author={Riachi, Jawad}, 
  year={2013}, 
  month={Nov},
  howpublished={\url{https://the.me/z-depth-map-expanding-exif-data-for-more-powerful-post-processing/}}
} 

@article{DDPG,
  title={Deep deterministic policy gradient for urban traffic light control},
  author={Casas, Noe},
  journal={arXiv preprint arXiv:1703.09035},
  year={2017}
}

@article{DepthAndStackResearch,
  title={Towards monocular vision based obstacle avoidance through deep reinforcement learning},
  author={Xie, Linhai and Wang, Sen and Markham, Andrew and Trigoni, Niki},
  journal={arXiv preprint arXiv:1706.09829},
  year={2017}
}

@article{iowamasterthesis,
  title={Visual object tracking for UAVs using deep reinforcement learning},
  author={Ko, Kyungtae},
  year={2020}
}

@article{lidarinselfdrivingcar,
issn = {1047-6938},
journal = {Optics and photonics news},
pages = {26},
volume = {29},
number = {1},
year = {2018},
title = {Lidar for Self-Driving Cars},
language = {eng},
author = {Hecht, Jeff},
}

@article{fasterrcnn,
issn = {0162-8828},
abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network(RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features-using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3], our detection system has a frame rate of 5 fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
pages = {1137--1149},
volume = {39},
publisher = {IEEE},
number = {6},
year = {2017},
title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
copyright = {Copyright 2017 Elsevier B.V., All rights reserved.},
language = {eng},
address = {United States},
author = {Shaoqing Ren and Kaiming He and Girshick, Ross and Jian Sun},
keywords = {Convolutional codes ; Training ; convolutional neural network ; Object detection ; Detectors ; Feature extraction ; Search problems ; Proposals ; region proposal ; Usage ; Algorithms ; Neural networks ; Analysis},
}

@article{LSTMinRL,
  title={Deep reinforcement learning approach for autonomous vehicle systems for maintaining security and safety using LSTM-GAN},
  author={Rasheed, Iftikhar and Hu, Fei and Zhang, Lin},
  journal={Vehicular Communications},
  volume={26},
  pages={100266},
  year={2020},
  publisher={Elsevier}
}

@article{NeuralNetworkApplications,
  title={State-of-the-art in artificial neural network applications: A survey},
  author={Abiodun, Oludare Isaac and Jantan, Aman and Omolara, Abiodun Esther and Dada, Kemi Victoria and Mohamed, Nachaat AbdElatif and Arshad, Humaira},
  journal={Heliyon},
  volume={4},
  number={11},
  pages={e00938},
  year={2018},
  publisher={Elsevier}
}

@article{CNNapplications2,
  title={A guide to convolutional neural networks for computer vision},
  author={Khan, Salman and Rahmani, Hossein and Shah, Syed Afaq Ali and Bennamoun, Mohammed},
  journal={Synthesis Lectures on Computer Vision},
  volume={8},
  number={1},
  pages={1--207},
  year={2018},
  publisher={Morgan \& Claypool Publishers}
}

@article{CNNapplications,
  title={Applications of deep convolutional neural network in computer vision},
  author={Hongtao, Lu and Qinchuan, Zhang},
  journal={Journal of Data Acquisition and Processing},
  volume={31},
  number={1},
  pages={1--17},
  year={2016}
}

@article{CNNintroduction,
  title={An introduction to convolutional neural networks},
  author={O'Shea, Keiron and Nash, Ryan},
  journal={arXiv preprint arXiv:1511.08458},
  year={2015}
}



@article{fastrcnn,
  author    = {Ross B. Girshick},
  title     = {Fast {R-CNN}},
  journal   = {CoRR},
  volume    = {abs/1504.08083},
  year      = {2015},
  howpublished={\url{http://arxiv.org/abs/1504.08083}},
  archivePrefix = {arXiv},
  eprint    = {1504.08083},
  timestamp = {Mon, 13 Aug 2018 16:49:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Girshick15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DQNasBenchmark,
  title={Implementing the deep q-network},
  author={Roderick, Melrose and MacGlashan, James and Tellex, Stefanie},
  journal={arXiv preprint arXiv:1711.07478},
  year={2017}
}


@inproceedings{original-rcnn,
issn = {1063-6919},
abstract = {Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.},
pages = {580--587},
publisher = {IEEE},
isbn = {9781479951185},
year = {2014},
title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
language = {eng},
author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
keywords = {Training ; Support vector machines ; Visualization ; Object detection ; Feature extraction ; Vectors ; Proposals},
}



@article{application3sports,
  title={Motion tracking drone for extreme sports filming},
  author={Iastrebov, Viatcheslav and Wong, Choon Yue and Pang, Wee Ching and Seet, Gerald},
  year={2014}
}

@inproceedings{ParrotARDrone,
  title={Any object tracking and following by a flying drone},
  author={Bartak, Roman and Vykovsk{\`y}, Adam},
  booktitle={2015 Fourteenth Mexican International Conference on Artificial Intelligence (MICAI)},
  pages={35--41},
  year={2015},
  organization={IEEE}
}

@article{RLfortakeoff,
  title={Accuracy Improvement of Autonomous Straight Take-off, Flying Forward, and Landing of a Drone with Deep Reinforcement Learning},
  author={Chang, Che-Cheng and Tsai, Jichiang and Lu, Peng-Chen and Lai, Chuan-An},
  journal={International Journal of Computational Intelligence Systems},
  volume={13},
  number={1},
  pages={914--919},
  year={2020},
  publisher={Atlantis Press}
}

@article{YOLOv4,
  title={YOLOv4: Optimal Speed and Accuracy of Object Detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@inproceedings{nonsparserewardissuboptimal,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6292--6299},
  year={2018},
  organization={IEEE}
}

@article{sparserewardsarebetter,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@inproceedings{AirSimDroneNavigation,
  title={Drone Navigation and Avoidance of Obstacles Through Deep Reinforcement Learning},
  author={{\c{C}}etin, Ender and Barrado, Cristina and Mu{\~n}oz, Guillem and Macias, Miquel and Pastor, Enric},
  booktitle={2019 IEEE/AIAA 38th Digital Avionics Systems Conference (DASC)},
  pages={1--7},
  year={2019},
  organization={IEEE}
}

@article{TakeOffFlyForwardusingRL,
  title={Accuracy Improvement of Autonomous Straight Take-off, Flying Forward, and Landing of a Drone with Deep Reinforcement Learning},
  author={Chang, Che-Cheng and Tsai, Jichiang and Lu, Peng-Chen and Lai, Chuan-An},
  journal={International Journal of Computational Intelligence Systems},
  volume={13},
  number={1},
  pages={914--919},
  year={2020},
  publisher={Atlantis Press}
}

@inproceedings{ObstacleAvoidance,
  title={Development of autonomous drones for adaptive obstacle avoidance in real world environments},
  author={Devos, Arne and Ebeid, Emad and Manoonpong, Poramate},
  booktitle={2018 21st Euromicro Conference on Digital System Design (DSD)},
  pages={707--710},
  year={2018},
  organization={IEEE}
}

@article{VisualGPS,
  title={Visual-GPS combined ‘follow-me’tracking for selfie drones},
  author={Do, T Tuan and Ahn, Heejune},
  journal={Advanced Robotics},
  volume={32},
  number={19},
  pages={1047--1060},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{DeepRLforNavUsingSensor,
  title={Deep reinforcement learning for drone navigation using sensor data},
  author={Hodge, Victoria J and Hawkins, Richard and Alexander, Rob},
  journal={Neural Computing and Applications},
  pages={1--19},
  year={2020},
  publisher={Springer}
}

@article{Hossain,
  title={Deep learning-based real-time multiple-object detection and tracking from aerial imagery via a flying robot with GPU-based embedded devices},
  author={Hossain, Sabir and Lee, Deok-jin},
  journal={Sensors},
  volume={19},
  number={15},
  pages={3371},
  year={2019},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{haarcascades,
  title={Rapid object detection using a boosted cascade of simple features},
  author={Viola, Paul and Jones, Michael},
  booktitle={Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001},
  volume={1},
  pages={I--I},
  year={2001},
  organization={IEEE}
}

@INPROCEEDINGS{HOGdetection,
  author={N. {Dalal} and B. {Triggs}},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Histograms of oriented gradients for human detection}, 
  year={2005},
  volume={1},
  number={},
  pages={886-893 vol. 1},
  doi={10.1109/CVPR.2005.177}
}

@INPROCEEDINGS{yolov3-tiny,
  author={P. {Adarsh} and P. {Rathi} and M. {Kumar}},
  booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={YOLO v3-Tiny: Object Detection and Recognition using one stage improved model}, 
  year={2020},
  volume={},
  number={},
  pages={687-694},
  doi={10.1109/ICACCS48705.2020.9074315}}

@inproceedings{yolo9000,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7263--7271},
  year={2017}
}

@article{yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@inproceedings{airsim,
  author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor},
  title = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles},
  year = {2017},
  booktitle = {Field and Service Robotics},
  eprint = {arXiv:1705.05065},
  howpublished={\url{https://arxiv.org/abs/1705.05065}}
}

@misc{unrealengine, 
  title={Unreal Engine: The most powerful real-time 3D creation platform}, 
  howpublished={\url{https://www.unrealengine.com/en-US/}}, 
  journal={Unreal Engine}
}

@misc{TPU, 
  title={Get started with the USB Accelerator}, 
  howpublished={\url{https://coral.ai/docs/accelerator/get-started/#requirements}}, 
  journal={Coral}, 
  author={Coral}
}

@misc{raspberrycam, 
  title={Buy a Camera Module V2}, 
  howpublished={\url{https://www.raspberrypi.org/products/camera-module-v2/?resellerType=home}}, 
  journal={Raspberry Pi}, 
  author={Raspberry Pi}, 
  year={2016}, 
  month
  ={Apr}
}
@inproceedings{originalyolo,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@inproceedings{YOLO-Lite,
  title={YOLO-LITE: a real-time object detection algorithm optimized for non-GPU computers},
  author={Huang, Rachel and Pedoeem, Jonathan and Chen, Cuixian},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)},
  pages={2503--2510},
  year={2018},
  organization={IEEE}
}

@article{cloudcomputingdrone,
  title={Dronetrack: Cloud-based real-time object tracking using unmanned aerial vehicles over the internet},
  author={Koub{\^a}a, Anis and Qureshi, Basit},
  journal={IEEE Access},
  volume={6},
  pages={13810--13824},
  year={2018},
  publisher={IEEE}
}

@article{RLenLSTMfordrone,
  title={End-to-end active object tracking and its real-world deployment via reinforcement learning},
  author={Luo, Wenhan and Sun, Peng and Zhong, Fangwei and Liu, Wei and Zhang, Tong and Wang, Yizhou},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={6},
  pages={1317--1332},
  year={2019},
  publisher={IEEE}
}

@article{acousticdronefollower,
  title={The development of an autonomous navigation system with optimal control of an UAV in partly unknown indoor environment},
  author={Mac, Thi Thoa and Copot, Cosmin and De Keyser, Robin and Ionescu, Clara M},
  journal={Mechatronics},
  volume={49},
  pages={187--196},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{blindrunnersdrone,
  title={Exploring the use of a drone to guide blind runners},
  author={Al Zayer, Majed and Tregillus, Sam and Bhandari, Jiwan and Feil-Seifer, Dave and Folmer, Eelke},
  booktitle={Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility},
  pages={263--264},
  year={2016}
}

@inproceedings{DroneFollowUsingPhone,
  title={Indoor follow me drone},
  author={Mao, Wenguang and Zhang, Zaiwei and Qiu, Lili and He, Jian and Cui, Yuchen and Yun, Sangki},
  booktitle={Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
  pages={345--358},
  year={2017}
}

@article{flightwithtrack,
  title={Flight Coordination of MAVs in GPS-denied Environments using a Metric Visual SLAM},
  author={Rojas-Perez, L Oyuki and Martinez-Carranza, J}
}

@article{DroneFollowMobileObject,
  title={Visual detection and tracking with UAVs, following a mobile object},
  author={Mercado-Ravell, Diego A and Castillo, Pedro and Lozano, Rogelio},
  journal={Advanced Robotics},
  volume={33},
  number={7-8},
  pages={388--402},
  year={2019},
  publisher={Taylor \& Francis}
}

@inproceedings{PowerlineFollower,
  title={Autonomous Drone-Based Powerline Insulator Inspection via Deep Learning},
  author={Muhammad, Anas and Shahpurwala, Adnan and Mukhopadhyay, Shayok and El-Hag, Ayman H},
  booktitle={Iberian Robotics conference},
  pages={52--62},
  year={2019},
  organization={Springer}
}

@article{FrontalViewRL,
  title={Continuous drone control using deep reinforcement learning for frontal view person shooting},
  author={Passalis, Nikolaos and Tefas, Anastasios},
  journal={Neural Computing and Applications},
  pages={1--12},
  year={2019},
  publisher={Springer}
}

@misc{rlisweird, 
  title={Faulty Reward Functions in the Wild}, 
  howpublished={\url{https://openai.com/blog/faulty-reward-functions/}},
  journal={OpenAI}, 
  publisher={OpenAI}, 
  author={Clark, 
  Jack and Amodei, Dario}, 
  year={2016}, 
  month={Dec}
} 

@article{riseofrl,
  title={Reinforcement learning, fast and slow},
  author={Botvinick, Matthew and Ritter, Sam and Wang, Jane X and Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis},
  journal={Trends in cognitive sciences},
  volume={23},
  number={5},
  pages={408--422},
  year={2019},
  publisher={Elsevier}
}

@misc{stereovision, 
  title={Comparing Three Prevalent 3D Imaging Technologies}, 
  howpublished={https://www.revopoint3d.com/comparing-three-prevalent-3d-imaging-technologies-tof-structured-light-and-binocular-stereo-vision/}, 
  journal={Revopoint 3D Technologies Inc.}, 
  author={3D, About the Author: Revopoint},
  year={2019}, 
  month={Nov}
}

@inproceedings{DepthFromMonocularImage,
  title={Learning depth from single monocular images},
  author={Saxena, Ashutosh and Chung, Sung H and Ng, Andrew Y},
  booktitle={Advances in neural information processing systems},
  pages={1161--1168},
  year={2006}
}

 @misc{arduino, 
  title={Arduino}, 
  howpublished={\url{https://www.arduino.cc/}}, 
  journal={Arduino}
} 

@article{rewardshapingcomplex,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

@article{pruning,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@article{pruningmeta,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
  journal={arXiv preprint arXiv:2003.03033},
  year={2020}
}

@article{HER,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={5048--5058},
  year={2017}
}

@techreport{rewardshaping,
  title={Theory and application of reward shaping in reinforcement learning},
  author={Laud, Adam Daniel},
  year={2004}
}

@article{rainbowrl,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  journal={arXiv preprint arXiv:1710.02298},
  year={2017}
}

@article{pretrainingfinetuning,
  title={A survey on image data augmentation for deep learning},
  author={Shorten, Connor and Khoshgoftaar, Taghi M},
  journal={Journal of Big Data},
  volume={6},
  number={1},
  pages={60},
  year={2019},
  publisher={Springer}
}

@incollection{stereovisiontheory,
  title = "2 - Basics of Autonomous Vehicles",
  editor = "Rahul Kala",
  booktitle = "On-Road Intelligent Vehicles",
  publisher = "Butterworth-Heinemann",
  pages = "11 - 35",
  year = "2016",
  isbn = "978-0-12-803729-4",
  doi = "https://doi.org/10.1016/B978-0-12-803729-4.00002-7",
  howpublished={\url{http://www.sciencedirect.com/science/article/pii/B9780128037294000027}},
  author = "Rahul Kala",
  keywords = "Autonomous vehicles, Control, Intelligent vehicles, Localization, Mobile robotics, Motion planning, Sensing, Vision",
  abstract = "The technology behind autonomous vehicles is interesting and challenging. The chapter, in a nutshell, discusses the complete technology and shows how autonomous vehicles get the capability to navigate autonomously in traffic scenarios. The hardware of autonomous vehicles, from a computational perspective, consists of sensors including vision cameras, RADARs, ultrasonics and LIDARs, along with an Inertial Measurement Unit and motion encoders to enable the vehicles estimate the position. The vehicles are driven with the help of steering, brake and throttle using the drive-by-wire technology which facilitates driving using computer programmes. The vision systems are responsible for looking at the operational scenario and making inferences, which are used to make the map of the world by a mapping module. The localization module uses the vision and map information to estimate the vehicle's pose. Motion-planning algorithms do all the decision-making including computing trajectories for operation, which are followed by using control algorithms."
}

@misc{rmsprop, 
  place={Toronto}, 
  title={Lecture 6a: Overview of mini-batch gradient descent}, 
  journal={Neural Networks for Machine Learning}, 
  author={Hinton, Geoffrey}, 
  year={2021}, 
  month={Mar}
}

 @misc{factoryenvironment, 
  title={Factory Environment Collection in Environments - UE Marketplace}, 
  howpublished={\url{https://www.unrealengine.com/marketplace/en-US/product/factory-environment-collection?sessionInvalidated=true}}, 
  journal={Unreal Engine}, 
  publisher={Epic Games}, 
  author={Rutkovskyi, Denys}, 
  year={2020}, 
  month={Jul}} 

@article{FastDepthandObstacleAvoidanceOnMonocularDrone,
  title={Fast Depth Prediction and Obstacle Avoidance on a Monocular Drone Using Probabilistic Convolutional Neural Network},
  author={Yang, Xin and Chen, Jingyu and Dang, Yuanjie and Luo, Hongcheng and Tang, Yuesheng and Liao, Chunyuan and Chen, Peng and Cheng, Kwang-Ting},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2019},
  publisher={IEEE}
}

@article{Mixed-Yolo_Lite,
  title={Mixed YOLOv3-LITE: A lightweight real-time object detection method},
  author={Zhao, Haipeng and Zhou, Yang and Zhang, Long and Peng, Yangzhao and Hu, Xiaofei and Peng, Haojie and Cai, Xinyue},
  journal={Sensors},
  volume={20},
  number={7},
  pages={1861},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@misc{yolofastest,
    author = {qiuqiuqiu},
    year = {2020},
    title = {Yolo-Fastest},
    subtitle = {Fact Sheet N°282},
    howpublished={\url{https://zhuanlan.zhihu.com/p/234506503}},
    note = {Accessed = 2020} 
}

@article{DQNDeepmind,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{DDQN,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  journal={arXiv preprint arXiv:1509.06461},
  year={2015}
}

 @misc{riseofdrones, 
  title={Rise of the drones}, 
  journal={AGCS Global}, 
  publisher={Allianz}, 
  year={2016}, 
  month={Sep},
  howpublished={\url{https://www.agcs.allianz.com/news-and-insights/reports/rise-of-the-drones.html}},
} 